"""
v1.4.0 --> v1.4.2 - database tables

$ docker exec -u postgres api-database psql -c "\dt;"
                   List of relations
 Schema |           Name            | Type  |  Owner
--------+---------------------------+-------+----------
 public | alembic_version           | table | postgres
 public | announcements             | table | postgres  <-- announcements-v<VERSION>.json
 public | groups                    | table | postgres  <-- groups-v<VERSION>.json
 public | people                    | table | postgres  <-- people-v<VERSION>.json
 public | people_email_addresses    | table | postgres  <-- people_email_addresses-v<VERSION>.json
 public | people_organizations      | table | postgres  <-- people_organizations-v<VERSION>.json
 public | people_roles              | table | postgres  <-- people_roles-v<VERSION>.json
 public | preferences               | table | postgres  <-- preferences-v<VERSION>.json
 public | profiles_keywords         | table | postgres  <-- profiles_keywords-v<VERSION>.json
 public | profiles_other_identities | table | postgres  <-- profiles_other_identities-v<VERSION>.json
 public | profiles_people           | table | postgres  <-- profiles_people-v<VERSION>.json
 public | profiles_personal_pages   | table | postgres  <-- profiles_personal_pages-v<VERSION>.json
 public | profiles_projects         | table | postgres  <-- profiles_projects-v<VERSION>.json
 public | profiles_references       | table | postgres  <-- profiles_references-v<VERSION>.json
 public | projects                  | table | postgres  <-- projects-v<VERSION>.json
 public | projects_creators         | table | postgres  <-- generated by db_restore_from_export
 public | projects_members          | table | postgres  <-- generated by db_restore_from_export
 public | projects_owners           | table | postgres  <-- generated by db_restore_from_export
 public | projects_tags             | table | postgres  <-- projects_tags-v<VERSION>.json
 public | sshkeys                   | table | postgres  <-- sshkeys-v<VERSION>.json
 public | testbed_info              | table | postgres  <-- testbed_info-v<VERSION>.json
(21 rows)

Changes from v1.4.0 --> v1.4.2
 public | projects                  | table | postgres
 - add: expires_on = db.Column(db.DateTime(timezone=True), nullable=True)
 - add: is_locked = db.Column(db.Boolean, default=False, nullable=False)
"""

import json
import os
from datetime import datetime, timedelta, timezone

from sqlalchemy import text, update
from sqlalchemy.dialects.postgresql import insert

from swagger_server.__main__ import app
from swagger_server.api_logger import consoleLogger
from swagger_server.database.db import db
from swagger_server.database.models.projects import FabricProjects
from swagger_server.response_code.core_api_utils import normalize_date_to_utc

# API version of data to restore from
api_version = '1.4.0'

# relative to the top level of the repository
BACKUP_DATA_DIR = os.getcwd() + '/server/swagger_server/backup/data'


# export alembic_version as JSON output file
def restore_alembic_version_data():
    """
    alembic_version
    - version_num = String
    """
    with open(BACKUP_DATA_DIR + '/alembic_version-v{0}.json'.format(api_version), 'r') as infile:
        alembic_version_dict = json.load(infile)
    alembic_version = alembic_version_dict.get('alembic_version')
    for a in alembic_version:
        stmt = update(db.Table('alembic_version')).values(
            version_num=a.get('version_num')
        )
        db.session.execute(stmt)
    db.session.commit()


# export announcements as JSON output file
def restore_announcements_data():
    """
    FabricAnnouncements(BaseMixin, TimestampMixin, TrackingMixin, db.Model):
    - announcement_type = db.Column(db.Enum(EnumAnnouncementTypes),default=EnumAnnouncementTypes.facility)
    - button = db.Column(db.String())
    - content = db.Column(db.String(), nullable=False)
    - created = db.Column(db.DateTime(timezone=True), nullable=False, default=datetime.now(timezone.utc))
    - created_by_uuid = db.Column(db.String(), nullable=True)
    - display_date = db.Column(db.DateTime(timezone=True), nullable=True)
    - end_date = db.Column(db.DateTime(timezone=True), nullable=True)
    - id = db.Column(db.Integer, nullable=False, primary_key=True)
    - is_active = db.Column(db.Boolean, default=True, nullable=False)
    - link = db.Column(db.String())
    - modified = db.Column(db.DateTime(timezone=True), nullable=True, onupdate=datetime.now(timezone.utc))
    - modified_by_uuid = db.Column(db.String(), nullable=True)
    - start_date = db.Column(db.DateTime(timezone=True), nullable=False)
    - title = db.Column(db.String(), nullable=False)
    - uuid = db.Column(db.String(), primary_key=False, nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/announcements-v{0}.json'.format(api_version), 'r') as infile:
        announcements_dict = json.load(infile)
    announcements = announcements_dict.get('announcements')
    max_id = 0
    for a in announcements:
        t_id = int(a.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('announcements')).values(
            announcement_type=a.get('announcement_type'),
            button=a.get('button'),
            content=a.get('content'),
            created=normalize_date_to_utc(a.get('created')) if a.get('created') else None,
            created_by_uuid=a.get('created_by_uuid'),
            display_date=normalize_date_to_utc(a.get('display_date')) if a.get('display_date') else None,
            end_date=normalize_date_to_utc(a.get('end_date')) if a.get('end_date') else None,
            id=t_id,
            is_active=a.get('is_active'),
            link=a.get('link'),
            modified=normalize_date_to_utc(a.get('modified')) if a.get('modified') else None,
            modified_by_uuid=a.get('modified_by_uuid'),
            start_date=normalize_date_to_utc(a.get('start_date')) if a.get('start_date') else None,
            title=a.get('title'),
            uuid=a.get('uuid'),
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='announcements', seq_value=max_id + 1)


# export groups as JSON output file
def restore_groups_data():
    """
    FabricGroups(BaseMixin, TimestampMixin, db.Model)
    - co_cou_id = db.Column(db.Integer, nullable=False)
    - co_parent_cou_id = db.Column(db.Integer, nullable=True)
    - created = db.Column(db.DateTime(timezone=True), nullable=False, default=datetime.now(timezone.utc))
    - deleted = db.Column(db.Boolean, default=False, nullable=False)
    - description = db.Column(db.Text, nullable=True)
    - id = db.Column(db.Integer, nullable=False, primary_key=True)
    - modified = db.Column(db.DateTime(timezone=True), nullable=True, onupdate=datetime.now(timezone.utc))
    - name = db.Column(db.String(), nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/groups-v{0}.json'.format(api_version), 'r') as infile:
        groups_dict = json.load(infile)
    groups = groups_dict.get('groups')
    max_id = 0
    for g in groups:
        t_id = int(g.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('groups')).values(
            co_cou_id=int(g.get('co_cou_id')),
            co_parent_cou_id=int(g.get('co_parent_cou_id')) if g.get('co_parent_cou_id') else None,
            created=normalize_date_to_utc(g.get('created')) if g.get('created') else None,
            deleted=g.get('deleted'),
            description=g.get('description'),
            id=t_id,
            modified=normalize_date_to_utc(g.get('modified')) if g.get('modified') else None,
            name=g.get('name')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='groups', seq_value=max_id + 1)


# export people as JSON output file
def restore_people_data():
    """
    FabricPeople(BaseMixin, TimestampMixin, db.Model)
    - * active = db.Column(db.Boolean, nullable=False, default=False)
    - * co_person_id = db.Column(db.Integer, nullable=True)
    - * created = db.Column(db.DateTime(timezone=True), nullable=False, default=datetime.now(timezone.utc))
    - * display_name = db.Column(db.String(), nullable=False)
    - email_addresses = db.relationship('EmailAddresses', backref='people', lazy=True)
    - * eppn = db.Column(db.String(), nullable=True)
    - * fabric_id = db.Column(db.String(), nullable=True)
    - * id = db.Column(db.Integer, nullable=False, primary_key=True)
    - * modified = db.Column(db.DateTime(timezone=True), nullable=True, onupdate=datetime.now(timezone.utc))
    - * oidc_claim_email = db.Column(db.String(), nullable=True)
    - * oidc_claim_family_name = db.Column(db.String(), nullable=True)
    - * oidc_claim_given_name = db.Column(db.String(), nullable=True)
    - * oidc_claim_name = db.Column(db.String(), nullable=True)
    - * oidc_claim_sub = db.Column(db.String(), nullable=True)
    - * org_affiliation = db.Column(db.Integer, db.ForeignKey('people_organizations.id'), nullable=True)
    - preferences = db.relationship('FabricPreferences', backref='people', lazy=True)
    - * preferred_email = db.Column(db.String(), nullable=False)
    - profile = db.relationship('FabricProfilesPeople', backref='people', uselist=False, lazy=True)
    # - publications = db.relationship('Publications', secondary=publications)
    - * registered_on = db.Column(db.DateTime(timezone=True), nullable=False, default=datetime.now(timezone.utc))
    - roles = db.relationship('FabricRoles', backref='people', lazy=True)
    - sshkeys = db.relationship('FabricSshKeys', backref='people', lazy=True)
    - * updated = db.Column(db.DateTime(timezone=True), nullable=False)
    - * uuid = db.Column(db.String(), primary_key=False, nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/people-v{0}.json'.format(api_version), 'r') as infile:
        people_dict = json.load(infile)
    people = people_dict.get('people')
    max_id = 0
    for p in people:
        t_id = int(p.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('people')).values(
            active=int(p.get('active')),
            co_person_id=int(p.get('co_person_id')) if p.get('co_person_id') else None,
            created=normalize_date_to_utc(p.get('created')),
            display_name=p.get('display_name'),
            # email_addresses=p.get('email_addresses'), <-- restore_people_email_addresses_data()
            eppn=p.get('eppn') if p.get('eppn') else None,
            fabric_id=p.get('fabric_id') if p.get('fabric_id') else None,
            id=t_id,
            modified=normalize_date_to_utc(p.get('modified')) if p.get('modified') else None,
            oidc_claim_email=p.get('oidc_claim_email') if p.get('oidc_claim_email') else None,
            oidc_claim_family_name=p.get('oidc_claim_family_name') if p.get('oidc_claim_family_name') else None,
            oidc_claim_given_name=p.get('oidc_claim_given_name') if p.get('oidc_claim_given_name') else None,
            oidc_claim_name=p.get('oidc_claim_name') if p.get('oidc_claim_name') else None,
            oidc_claim_sub=p.get('oidc_claim_sub') if p.get('oidc_claim_sub') else None,
            org_affiliation=int(p.get('org_affiliation')) if p.get('org_affiliation') else None,
            # preferences=p.get('preferences'), <-- restore_preferences_data()
            preferred_email=p.get('preferred_email'),
            # profile=p.get('profile.id'), <-- restore_profiles_people_data()
            registered_on=normalize_date_to_utc(p.get('registered_on')) if p.get('registered_on') else None,
            # roles=p.get('roles'), <-- restore_people_roles_data()
            # sshkeys=p.get('sshkeys'), <-- restore_sshkeys_data()
            updated=normalize_date_to_utc(p.get('updated')) if p.get('updated') else None,
            uuid=p.get('uuid')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='people', seq_value=max_id + 1)


# export people_email_addresses as JSON output file
def restore_people_email_addresses_data():
    """
    EmailAddresses(BaseMixin, db.Model)
    - co_email_address_id = db.Column(db.Integer)
    - email = db.Column(db.String())
    - id = db.Column(db.Integer, nullable=False, primary_key=True)
    - people_id = db.Column(db.Integer, db.ForeignKey('people.id'), nullable=False)
    - type = db.Column(db.String())
    """
    with open(BACKUP_DATA_DIR + '/people_email_addresses-v{0}.json'.format(api_version), 'r') as infile:
        people_email_addresses_dict = json.load(infile)
    people_email_addresses = people_email_addresses_dict.get('people_email_addresses')
    max_id = 0
    for e in people_email_addresses:
        t_id = int(e.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('people_email_addresses')).values(
            co_email_address_id=int(e.get('co_email_address_id')),
            email=e.get('email'),
            id=t_id,
            people_id=int(e.get('people_id')),
            type=e.get('type')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='people_email_addresses', seq_value=max_id + 1)


# export people_organizations as JSON output file
def restore_people_organizations_data():
    """
    Organizations(BaseMixin, db.Model)
    - affiliation = db.Column(db.String(), nullable=False)
    - id = db.Column(db.Integer, nullable=False, primary_key=True)
    - org_identity_id = db.Column(db.Integer)
    - organization = db.Column(db.String(), nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/people_organizations-v{0}.json'.format(api_version), 'r') as infile:
        people_organizations_dict = json.load(infile)
    people_organizations = people_organizations_dict.get('people_organizations')
    max_id = 0
    for o in people_organizations:
        t_id = int(o.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('people_organizations')).values(
            affiliation=o.get('affiliation'),
            id=t_id,
            org_identity_id=int(o.get('org_identity_id')),
            organization=o.get('organization')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='people_organizations', seq_value=max_id + 1)


# export people_roles as JSON output file
def restore_people_roles_data():
    """
    FabricRoles(BaseMixin, db.Model)
    - affiliation = db.Column(db.String(), nullable=False)
    - co_cou_id = db.Column(db.Integer, nullable=False)
    - co_person_id = db.Column(db.Integer, nullable=False)
    - co_person_role_id = db.Column(db.Integer, nullable=False)
    - id = db.Column(db.Integer, nullable=False, primary_key=True)
    - name = db.Column(db.String(), nullable=False)
    - description = db.Column(db.String(), nullable=True)
    - people_id = db.Column(db.Integer, db.ForeignKey('people.id'), nullable=False)
    - status = db.Column(db.String(), nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/people_roles-v{0}.json'.format(api_version), 'r') as infile:
        people_roles_dict = json.load(infile)
    people_roles = people_roles_dict.get('people_roles')
    max_id = 0
    for r in people_roles:
        t_id = int(r.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('people_roles')).values(
            affiliation=r.get('affiliation'),
            co_cou_id=int(r.get('co_cou_id')),
            co_person_id=int(r.get('co_person_id')),
            co_person_role_id=int(r.get('co_person_role_id')),
            id=t_id,
            name=r.get('name'),
            description=r.get('description') if r.get('description') else None,
            people_id=r.get('people_id'),
            status=r.get('status')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='people_roles', seq_value=max_id + 1)


# export preferences as JSON output file
def restore_preferences_data():
    """
    FabricPreferences(BaseMixin, TimestampMixin, db.Model)
    - created = db.Column(db.DateTime(timezone=True), nullable=False, default=datetime.now(timezone.utc))
    - id = db.Column(db.Integer, nullable=False, primary_key=True)
    - key = db.Column(db.String(), nullable=False)
    - modified = db.Column(db.DateTime(timezone=True), nullable=True, onupdate=datetime.now(timezone.utc))
    - people_id = db.Column(db.Integer, db.ForeignKey('people.id'), nullable=True)
    - profiles_people_id = db.Column(db.Integer, db.ForeignKey('profiles_people.id'), nullable=True)
    - profiles_projects_id = db.Column(db.Integer, db.ForeignKey('profiles_projects.id'), nullable=True)
    - projects_id = db.Column(db.Integer, db.ForeignKey('projects.id'), nullable=True)
    - type = db.Column(db.Enum(EnumPreferenceTypes), nullable=False)
    - value = db.Column(db.Boolean, default=True, nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/preferences-v{0}.json'.format(api_version), 'r') as infile:
        preferences_dict = json.load(infile)
    preferences = preferences_dict.get('preferences')
    max_id = 0
    for p in preferences:
        t_id = int(p.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('preferences')).values(
            created=normalize_date_to_utc(p.get('created')) if p.get('created') else None,
            id=t_id,
            key=p.get('key'),
            modified=normalize_date_to_utc(p.get('modified')) if p.get('modified') else None,
            people_id=int(p.get('people_id')) if p.get('people_id') else None,
            profiles_people_id=int(p.get('profiles_people_id')) if p.get('profiles_people_id') else None,
            profiles_projects_id=int(p.get('profiles_projects_id')) if p.get('profiles_projects_id') else None,
            projects_id=int(p.get('projects_id')) if p.get('projects_id') else None,
            type=p.get('type'),
            value=p.get('value')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='preferences', seq_value=max_id + 1)


# export profiles_keywords as JSON output file
def restore_profiles_keywords_data():
    """
    ProfilesKeywords(BaseMixin, db.Model)
    - id = db.Column(db.Integer, nullable=False, primary_key=True)
    - keyword = db.Column(db.String(), nullable=False)
    - profiles_projects_id = db.Column(db.Integer, db.ForeignKey('profiles_projects.id'), nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/profiles_keywords-v{0}.json'.format(api_version), 'r') as infile:
        profiles_keywords_dict = json.load(infile)
    profiles_keywords = profiles_keywords_dict.get('profiles_keywords')
    max_id = 0
    for p in profiles_keywords:
        t_id = int(p.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('profiles_keywords')).values(
            id=t_id,
            keyword=p.get('keyword'),
            profiles_projects_id=int(p.get('profiles_projects_id'))
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='profiles_keywords', seq_value=max_id + 1)


# export profiles_other_identities as JSON output file
def restore_profiles_other_identities_data():
    """
    ProfilesOtherIdentities(BaseMixin, db.Model)
    - id = db.Column(db.Integer, nullable=False, primary_key=True)
    - identity = db.Column(db.String(), nullable=False)
    - profiles_id = db.Column(db.Integer, db.ForeignKey('profiles_people.id'), nullable=False)
    - type = db.Column(db.String(), nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/profiles_other_identities-v{0}.json'.format(api_version), 'r') as infile:
        profiles_other_identities_dict = json.load(infile)
    profiles_other_identities = profiles_other_identities_dict.get('profiles_other_identities')
    max_id = 0
    for p in profiles_other_identities:
        t_id = int(p.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('profiles_other_identities')).values(
            id=t_id,
            identity=p.get('identity'),
            profiles_id=int(p.get('profiles_id')),
            type=p.get('type')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='profiles_other_identities', seq_value=max_id + 1)


# export profiles_people as JSON output file
def restore_profiles_people_data():
    """
    FabricProfilesPeople(BaseMixin, TimestampMixin, db.Model):
    - * bio = db.Column(db.String(), nullable=True)
    - * created = db.Column(db.DateTime(timezone=True), nullable=False, default=datetime.now(timezone.utc))
    - * cv = db.Column(db.String(), nullable=True)
    - * id = db.Column(db.Integer, nullable=False, primary_key=True)
    - * job = db.Column(db.String(), nullable=True)
    - * modified = db.Column(db.DateTime(timezone=True), nullable=True, onupdate=datetime.now(timezone.utc))
    - other_identities = db.relationship('ProfilesOtherIdentities', backref='profiles_people', lazy=True)
    - * people_id = db.Column(db.Integer, db.ForeignKey('people.id'), nullable=False)
    - personal_pages = db.relationship('ProfilesPersonalPages', backref='profiles_people', lazy=True)
    - preferences = db.relationship('FabricPreferences', backref='profiles_people', lazy=True)
    - * pronouns = db.Column(db.String(), nullable=True)
    - * uuid = db.Column(db.String(), primary_key=False, nullable=False)
    - * website = db.Column(db.String(), nullable=True)
    """
    with open(BACKUP_DATA_DIR + '/profiles_people-v{0}.json'.format(api_version), 'r') as infile:
        profiles_people_dict = json.load(infile)
    profiles_people = profiles_people_dict.get('profiles_people')
    max_id = 0
    for p in profiles_people:
        t_id = int(p.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('profiles_people')).values(
            bio=p.get('bio') if p.get('bio') else None,
            created=normalize_date_to_utc(p.get('created')) if p.get('created') else None,
            cv=p.get('cv') if p.get('cv') else None,
            id=t_id,
            job=p.get('job') if p.get('job') else None,
            modified=normalize_date_to_utc(p.get('modified')) if p.get('modified') else None,
            # other_identities=p.get('other_identities'), <-- restore_profiles_other_identities_data()
            people_id=int(p.get('people_id')),
            # personal_pages=p.get('personal_pages'), <-- restore_profiles_personal_pages_data()
            # preferences=p.get('preferences'), <-- restore_preferences_data()
            pronouns=p.get('pronouns') if p.get('pronouns') else None,
            uuid=p.get('uuid'),
            website=p.get('website') if p.get('website') else None
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='profiles_people', seq_value=max_id + 1)


# export profiles_personal_pages as JSON output file
def restore_profiles_personal_pages_data():
    """
    ProfilesPersonalPages(BaseMixin, db.Model)
    - id = db.Column(db.Integer, nullable=False, primary_key=True)
    - profiles_people_id = db.Column(db.Integer, db.ForeignKey('profiles_people.id'), nullable=False)
    - type = db.Column(db.String(), nullable=False)
    - url = db.Column(db.String(), nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/profiles_personal_pages-v{0}.json'.format(api_version), 'r') as infile:
        profiles_personal_pages_dict = json.load(infile)
    profiles_personal_pages = profiles_personal_pages_dict.get('profiles_personal_pages')
    max_id = 0
    for p in profiles_personal_pages:
        t_id = int(p.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('profiles_personal_pages')).values(
            id=t_id,
            profiles_people_id=int(p.get('profiles_people_id')),
            type=p.get('type'),
            url=p.get('url')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='profiles_personal_pages', seq_value=max_id + 1)


# export profiles_projects as JSON output file
def restore_profiles_projects_data():
    """
    FabricProfilesProjects(BaseMixin, TimestampMixin, db.Model):
    - * award_information = db.Column(db.String(), nullable=True)
    - * created = db.Column(db.DateTime(timezone=True), nullable=False, default=datetime.now(timezone.utc))
    - * goals = db.Column(db.String(), nullable=True)
    - * id = db.Column(db.Integer, nullable=False, primary_key=True)
    - keywords = db.relationship('ProfilesKeywords', backref='profiles_projects', lazy=True)
    - * modified = db.Column(db.DateTime(timezone=True), nullable=True, onupdate=datetime.now(timezone.utc))
    - preferences = db.relationship('FabricPreferences', backref='profiles_projects', lazy=True)
    - * project_status = db.Column(db.String(), nullable=True)
    - * projects_id = db.Column(db.Integer, db.ForeignKey('projects.id'), nullable=False)
    - * purpose = db.Column(db.String(), nullable=True)
    - references = db.relationship('ProfilesReferences', backref='profiles_projects', lazy=True)
    - * uuid = db.Column(db.String(), primary_key=False, nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/profiles_projects-v{0}.json'.format(api_version), 'r') as infile:
        profiles_projects_dict = json.load(infile)
    profiles_projects = profiles_projects_dict.get('profiles_projects')
    max_id = 0
    for p in profiles_projects:
        t_id = int(p.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('profiles_projects')).values(
            award_information=p.get('award_information') if p.get('award_information') else None,
            created=normalize_date_to_utc(p.get('created')) if p.get('created') else None,
            goals=p.get('goals') if p.get('goals') else None,
            id=t_id,
            # keywords=p.get('keywords'), <-- restore_profiles_keywords_data()
            modified=normalize_date_to_utc(p.get('modified')) if p.get('modified') else None,
            # preferences=p.get('preferences'), <-- restore_preferences_data()
            project_status=p.get('project_status') if p.get('project_status') else None,
            projects_id=int(p.get('projects_id')),
            purpose=p.get('purpose') if p.get('purpose') else None,
            # references=p.get('references'), <-- restore_profiles_references_data()
            uuid=p.get('uuid')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='profiles_projects', seq_value=max_id + 1)


# export profiles_references as JSON output file
def restore_profiles_references_data():
    """
    ProfilesReferences(BaseMixin, db.Model)
    - description = db.Column(db.String(), nullable=False)
    - id = db.Column(db.Integer, nullable=False, primary_key=True)
    - profiles_projects_id = db.Column(db.Integer, db.ForeignKey('profiles_projects.id'), nullable=False)
    - url = db.Column(db.String(), nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/profiles_references-v{0}.json'.format(api_version), 'r') as infile:
        profiles_references_dict = json.load(infile)
    profiles_references = profiles_references_dict.get('profiles_references')
    max_id = 0
    for p in profiles_references:
        t_id = int(p.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('profiles_references')).values(
            description=p.get('description'),
            id=t_id,
            profiles_projects_id=int(p.get('profiles_projects_id')),
            url=p.get('url')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='profiles_references', seq_value=max_id + 1)


# export projects as JSON output file
def restore_projects_data():
    """
    FabricProjects(BaseMixin, TimestampMixin, TrackingMixin, db.Model)
    - * active = db.Column(db.Boolean, default=True, nullable=False)
    - * co_cou_id_pc = db.Column(db.Integer, nullable=True)
    - * co_cou_id_pm = db.Column(db.Integer, nullable=True)
    - * co_cou_id_po = db.Column(db.Integer, nullable=True)
    - * created = db.Column(db.DateTime(timezone=True), nullable=False, default=datetime.now(timezone.utc))
    - * created_by_uuid = db.Column(db.String(), nullable=True)
    - * description = db.Column(db.Text, nullable=False)
    - * expires_on = db.Column(db.DateTime(timezone=True), nullable=True)
    - * facility = db.Column(db.String(), default=os.getenv('CORE_API_DEFAULT_FACILITY'), nullable=False)
    - * id = db.Column(db.Integer, nullable=False, primary_key=True)
    - * is_locked = db.Column(db.Boolean, default=False, nullable=False)
    - * is_public = db.Column(db.Boolean, default=True, nullable=False)
    - * modified = db.Column(db.DateTime(timezone=True), nullable=True, onupdate=datetime.now(timezone.utc))
    - * modified_by_uuid = db.Column(db.String(), nullable=True)
    - * name = db.Column(db.String(), nullable=False)
    - preferences = db.relationship('FabricPreferences', backref='projects', lazy=True)
    - profile = db.relationship('FabricProfilesProjects', backref='projects', uselist=False, lazy=True)
    - project_creators = db.relationship('FabricPeople', secondary=projects_creators)
    - project_members = db.relationship('FabricPeople', secondary=projects_members)
    - project_owners = db.relationship('FabricPeople', secondary=projects_owners)
    - tags = db.relationship('ProjectsTags', backref='projects', lazy=True)
    - * uuid = db.Column(db.String(), primary_key=False, nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/projects-v{0}.json'.format(api_version), 'r') as infile:
        projects_dict = json.load(infile)
    projects = projects_dict.get('projects')
    max_id = 0
    for p in projects:
        t_id = int(p.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('projects')).values(
            active=p.get('active'),
            co_cou_id_pc=int(p.get('co_cou_id_pc')) if p.get('co_cou_id_pc') else None,
            co_cou_id_pm=int(p.get('co_cou_id_pm')) if p.get('co_cou_id_pm') else None,
            co_cou_id_po=int(p.get('co_cou_id_po')) if p.get('co_cou_id_po') else None,
            created=normalize_date_to_utc(p.get('created')) if p.get('created') else None,
            created_by_uuid=p.get('created_by_uuid') if p.get('created_by_uuid') else None,
            description=p.get('description'),
            expires_on=normalize_date_to_utc(p.get('expires_on')) if p.get('expires_on') else None,
            facility=p.get('facility'),
            id=t_id,
            is_locked=p.get('is_locked') if p.get('is_locked') else False,
            is_public=p.get('is_public'),
            modified=normalize_date_to_utc(p.get('modified')) if p.get('modified') else None,
            modified_by_uuid=p.get('modified_by_uuid') if p.get('modified_by_uuid') else None,
            name=p.get('name'),
            # preferences=p.get('preferences'), <-- restore_preferences_data()
            # profile=p.get('profile.id'), <-- restore_projects_profiles_data()
            # project_creators=p.get('project_creators'), <-- restore_projects_creators_data()
            # project_members=p.get('project_members'), <-- restore_projects_members_data()
            # project_owners=p.get('project_owners'), <-- restore_projects_owners_data()
            # tags=p.get('tags'), <-- restore_projects_tags_data()
            uuid=p.get('uuid')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='projects', seq_value=max_id + 1)


# export projects_creators as JSON output file
def restore_projects_creators_data():
    """
    projects_creators
    - people_id = db.Column('people_id', db.Integer, db.ForeignKey('people.id'), primary_key=True),
    - projects_id = db.Column('projects_id', db.Integer, db.ForeignKey('projects.id'), primary_key=True)
    """
    with open(BACKUP_DATA_DIR + '/projects_creators-v{0}.json'.format(api_version), 'r') as infile:
        projects_creators_dict = json.load(infile)
    projects_creators = projects_creators_dict.get('projects_creators')
    for pc in projects_creators:
        stmt = insert(db.Table('projects_creators', metadata=db.Model.metadata)).values(
            people_id=pc.get('people_id'),
            projects_id=pc.get('projects_id')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()


# export projects_members as JSON output file
def restore_projects_members_data():
    """
    projects_members
    - people_id = db.Column('people_id', db.Integer, db.ForeignKey('people.id'), primary_key=True),
    - projects_id = db.Column('projects_id', db.Integer, db.ForeignKey('projects.id'), primary_key=True)
    """
    with open(BACKUP_DATA_DIR + '/projects_members-v{0}.json'.format(api_version), 'r') as infile:
        projects_members_dict = json.load(infile)
    projects_members = projects_members_dict.get('projects_members')
    for pc in projects_members:
        stmt = insert(db.Table('projects_members', metadata=db.Model.metadata)).values(
            people_id=pc.get('people_id'),
            projects_id=pc.get('projects_id')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()


# export projects_owners as JSON output file
def restore_projects_owners_data():
    """
    projects_owners
    - people_id = db.Column('people_id', db.Integer, db.ForeignKey('people.id'), primary_key=True),
    - projects_id = db.Column('projects_id', db.Integer, db.ForeignKey('projects.id'), primary_key=True)
    """
    with open(BACKUP_DATA_DIR + '/projects_owners-v{0}.json'.format(api_version), 'r') as infile:
        projects_owners_dict = json.load(infile)
    projects_owners = projects_owners_dict.get('projects_owners')
    for pc in projects_owners:
        stmt = insert(db.Table('projects_owners', metadata=db.Model.metadata)).values(
            people_id=pc.get('people_id'),
            projects_id=pc.get('projects_id')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()


# export projects_tags as JSON output file
def restore_projects_tags_data():
    """
    ProjectsTags(BaseMixin, db.Model)
    - id = db.Column(db.Integer, nullable=False, primary_key=True)
    - projects_id = db.Column(db.Integer, db.ForeignKey('projects.id'), nullable=False)
    - tag = db.Column(db.Text, nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/projects_tags-v{0}.json'.format(api_version), 'r') as infile:
        projects_tags_dict = json.load(infile)
    projects_tags = projects_tags_dict.get('projects_tags')
    max_id = 0
    for t in projects_tags:
        t_id = int(t.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('projects_tags')).values(
            id=t_id,
            projects_id=int(t.get('projects_id')),
            tag=t.get('tag')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='projects_tags', seq_value=max_id + 1)


# export sshkeys as JSON output file
def restore_sshkeys_data():
    """
    FabricSshKeys(BaseMixin, TimestampMixin, db.Model)
    - active = db.Column(db.Boolean, default=True, nullable=False)
    - comment = db.Column(db.String())
    - created = db.Column(db.DateTime(timezone=True), nullable=False, default=datetime.now(timezone.utc))
    - deactivated_on = db.Column(db.DateTime(timezone=True), nullable=True)
    - deactivated_reason = db.Column(db.String())
    - description = db.Column(db.String())
    - expires_on = db.Column(db.DateTime(timezone=True), nullable=False)
    - fabric_key_type = db.Column(db.Enum(EnumSshKeyTypes), default=EnumSshKeyTypes.sliver, nullable=False)
    - fingerprint = db.Column(db.String())
    - id = db.Column(db.Integer, nullable=False, primary_key=True)
    - modified = db.Column(db.DateTime(timezone=True), nullable=True, onupdate=datetime.now(timezone.utc))
    - people_id = db.Column(db.Integer, db.ForeignKey('people.id'), nullable=False)
    - public_key = db.Column(db.String())
    - ssh_key_type = db.Column(db.String())
    - status = db.Column(db.Enum(EnumSshKeyStatus), default=EnumSshKeyStatus.active, nullable=False)
    - uuid = db.Column(db.String(), primary_key=False, nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/sshkeys-v{0}.json'.format(api_version), 'r') as infile:
        sshkeys_dict = json.load(infile)
    sshkeys = sshkeys_dict.get('sshkeys')
    max_id = 0
    for k in sshkeys:
        t_id = int(k.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('sshkeys')).values(
            active=k.get('active'),
            comment=k.get('comment'),
            created=normalize_date_to_utc(k.get('created')),
            deactivated_on=normalize_date_to_utc(k.get('deactivated_on')) if k.get('deactivated_on') else None,
            deactivated_reason=k.get('deactivated_reason') if k.get('deactivated_reason') else None,
            description=k.get('description') if k.get('description') else None,
            expires_on=normalize_date_to_utc(k.get('expires_on')) if k.get('expires_on') else None,
            fabric_key_type=k.get('fabric_key_type'),
            fingerprint=k.get('fingerprint'),
            id=t_id,
            modified=normalize_date_to_utc(k.get('modified')) if k.get('modified') else None,
            people_id=int(k.get('people_id')),
            public_key=k.get('public_key'),
            ssh_key_type=k.get('ssh_key_type'),
            status=k.get('status'),
            uuid=k.get('uuid')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='sshkeys', seq_value=max_id + 1)


# export testbed_info as JSON output file
def restore_testbed_info_data():
    """
    FabricTestbedInfo(BaseMixin, TimestampMixin, TrackingMixin, db.Model)
    - created = db.Column(db.DateTime(timezone=True), nullable=False, default=datetime.now(timezone.utc))
    - created_by_uuid = db.Column(db.String(), nullable=True)
    - id = db.Column(db.Integer, nullable=False, primary_key=True)
    - is_active = db.Column(db.Boolean, default=True)
    - json_data = db.Column(JSONB, nullable=False)
    - modified = db.Column(db.DateTime(timezone=True), nullable=True, onupdate=datetime.now(timezone.utc))
    - modified_by_uuid = db.Column(db.String(), nullable=True)
    - uuid = db.Column(db.String(), primary_key=False, nullable=False)
    """
    with open(BACKUP_DATA_DIR + '/testbed_info-v{0}.json'.format(api_version), 'r') as infile:
        testbed_info_dict = json.load(infile)
    testbed_info = testbed_info_dict.get('testbed_info')
    max_id = 0
    for i in testbed_info:
        t_id = int(i.get('id'))
        if t_id > max_id:
            max_id = t_id
        stmt = insert(db.Table('testbed_info')).values(
            created=i.get('created') if i.get('created') else None,
            created_by_uuid=i.get('created_by_uuid') if i.get('created_by_uuid') else None,
            id=t_id,
            is_active=i.get('is_active'),
            json_data=i.get('json_data'),
            modified=i.get('modified') if i.get('modified') else None,
            modified_by_uuid=i.get('modified_by_uuid') if i.get('modified_by_uuid') else None,
            uuid=i.get('uuid')
        ).on_conflict_do_nothing()
        db.session.execute(stmt)
    db.session.commit()
    reset_serial_sequence(db_table='testbed_info', seq_value=max_id + 1)


# verify project expiry date
def verify_project_expiry():
    """
    FabricProjects(BaseMixin, TimestampMixin, TrackingMixin, db.Model)
    - active = db.Column(db.Boolean, default=True, nullable=False)
    - co_cou_id_pc = db.Column(db.Integer, nullable=True)
    - co_cou_id_pm = db.Column(db.Integer, nullable=True)
    - co_cou_id_po = db.Column(db.Integer, nullable=True)
    - created = db.Column(db.DateTime(timezone=True), nullable=False, default=datetime.now(timezone.utc))
    - created_by_uuid = db.Column(db.String(), nullable=True)
    - description = db.Column(db.Text, nullable=False)
    - expires_on = db.Column(db.DateTime(timezone=True), nullable=True)
    - facility = db.Column(db.String(), default=os.getenv('CORE_API_DEFAULT_FACILITY'), nullable=False)
    - id = db.Column(db.Integer, nullable=False, primary_key=True)
    - is_locked = db.Column(db.Boolean, default=False, nullable=False)
    - is_public = db.Column(db.Boolean, default=True, nullable=False)
    - modified = db.Column(db.DateTime(timezone=True), nullable=True, onupdate=datetime.now(timezone.utc))
    - modified_by_uuid = db.Column(db.String(), nullable=True)
    - name = db.Column(db.String(), nullable=False)
    - preferences = db.relationship('FabricPreferences', backref='projects', lazy=True)
    - profile = db.relationship('FabricProfilesProjects', backref='projects', uselist=False, lazy=True)
    - project_creators = db.relationship('FabricPeople', secondary=projects_creators)
    - project_members = db.relationship('FabricPeople', secondary=projects_members)
    - project_owners = db.relationship('FabricPeople', secondary=projects_owners)
    # - publications = db.relationship('Publications', secondary=publications)
    - tags = db.relationship('ProjectsTags', backref='projects', lazy=True)
    - uuid = db.Column(db.String(), primary_key=False, nullable=False)
    """
    fab_projects = FabricProjects.query.order_by('id').all()
    now = datetime.now(timezone.utc)
    project_expiry = now + timedelta(days=float(os.getenv('PROJECTS_RENEWAL_PERIOD_IN_DAYS')))
    for p in fab_projects:
        if not p.expires_on:
            # set new project expiry date
            p.expires_on = project_expiry
            p.modified = now
            db.session.commit()
            consoleLogger.info('Project: {0} set expiry: {1}'.format(str(p.uuid), str(project_expiry)))
        else:
            if p.expires_on < now:
                # set is_locked to True
                p.is_locked = True
                p.modified = now
                consoleLogger.info('Project: {0} is expired'.format(str(p.uuid)))


def reset_serial_sequence(db_table: str, seq_value: int):
    stmt = text('SELECT setval(pg_get_serial_sequence(\'{0}\',\'id\'),{1});'.format(db_table, str(seq_value)))
    db.session.execute(stmt)
    db.session.commit()
    consoleLogger.info('  - Table: {0}, sequence_id: {1}'.format(db_table, str(seq_value)))


if __name__ == '__main__':
    app.app_context().push()
    consoleLogger.info('Restorer for API version {0}'.format(api_version))
    #                    List of relations
    #  Schema |           Name            | Type  |  Owner
    # --------+---------------------------+-------+----------
    #  public | alembic_version           | table | postgres
    # consoleLogger.info('restore alembic_version table')
    # restore_alembic_version_data()

    #  public | announcements             | table | postgres
    consoleLogger.info('restore announcements table')
    restore_announcements_data()

    #  public | groups                    | table | postgres
    consoleLogger.info('restore groups table')
    restore_groups_data()

    #  public | people_organizations      | table | postgres
    consoleLogger.info('restore people_organizations table')
    restore_people_organizations_data()

    #  public | people                    | table | postgres
    consoleLogger.info('restore people table')
    restore_people_data()

    #  public | people_email_addresses    | table | postgres
    consoleLogger.info('restore people_email_addresses table')
    restore_people_email_addresses_data()

    #  public | people_roles              | table | postgres
    consoleLogger.info('restore people_roles table')
    restore_people_roles_data()

    #  public | profiles_people           | table | postgres
    consoleLogger.info('restore profiles_people table')
    restore_profiles_people_data()

    #  public | profiles_other_identities | table | postgres
    consoleLogger.info('restore profiles_other_identities table')
    restore_profiles_other_identities_data()

    #  public | profiles_personal_pages   | table | postgres
    consoleLogger.info('restore profiles_personal_pages table')
    restore_profiles_personal_pages_data()

    #  public | projects                  | table | postgres
    consoleLogger.info('restore projects table')
    restore_projects_data()

    #  public | profiles_projects         | table | postgres
    consoleLogger.info('restore profiles_projects table')
    restore_profiles_projects_data()

    #  public | profiles_keywords         | table | postgres
    consoleLogger.info('restore profiles_keywords table')
    restore_profiles_keywords_data()

    #  public | profiles_references       | table | postgres
    consoleLogger.info('restore profiles_references table')
    restore_profiles_references_data()

    #  public | projects_creators         | table | postgres
    consoleLogger.info('restore projects_creators table')
    restore_projects_creators_data()

    #  public | projects_members          | table | postgres
    consoleLogger.info('restore projects_members table')
    restore_projects_members_data()

    #  public | projects_owners           | table | postgres
    consoleLogger.info('restore projects_owners table')
    restore_projects_owners_data()

    #  public | projects_tags             | table | postgres
    consoleLogger.info('restore projects_tags table')
    restore_projects_tags_data()

    #  public | preferences               | table | postgres
    consoleLogger.info('restore preferences table')
    restore_preferences_data()

    #  public | sshkeys                   | table | postgres
    consoleLogger.info('restore sshkeys table')
    restore_sshkeys_data()

    #  public | testbed_info              | table | postgres
    consoleLogger.info('restore testbed_info table')
    restore_testbed_info_data()

    #  verify project expiry
    consoleLogger.info('verify project expiry')
    verify_project_expiry()
